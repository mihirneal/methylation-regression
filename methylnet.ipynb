{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from methylnet.schedulers import *\n",
    "from methylnet.plotter import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pymethylprocess.visualizations import umap_embed, plotly_plot\n",
    "import copy\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def train_vae(model, loader, loss_func, optimizer, cuda=True, epoch=0, kl_warm_up=0, beta=1.):\n",
    "\tmodel.train(True) \n",
    "\ttotal_loss,total_recon_loss,total_kl_loss=0.,0.,0.\n",
    "\tstop_iter = loader.dataset.length // loader.batch_size\n",
    "\ttotal_loss,total_recon_loss,total_kl_loss=0.,0.,0.\n",
    "\tfor i,(inputs, _) in enumerate(loader):\n",
    "\t\tif i == stop_iter:\n",
    "\t\t\tbreak\n",
    "\t\tinputs = Variable(inputs).view(inputs.size()[0],inputs.size()[1]) \n",
    "\t\tif cuda:\n",
    "\t\t\tinputs = inputs.cuda()\n",
    "\t\toutput, mean, logvar = model(inputs)\n",
    "\t\tloss, reconstruction_loss, kl_loss = vae_loss(output, inputs, mean, logvar, loss_func, epoch, kl_warm_up, beta)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\ttotal_loss+=loss.item()\n",
    "\t\ttotal_recon_loss+=reconstruction_loss.item()\n",
    "\t\ttotal_kl_loss+=kl_loss.item()\n",
    "\treturn model, total_loss,total_recon_loss,total_kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_vae(model, loader, loss_func, optimizer, cuda=True, epoch=0, kl_warm_up=0, beta=1.):\n",
    "\tmodel.eval() \n",
    "\tstop_iter = loader.dataset.length // loader.batch_size\n",
    "\ttotal_loss,total_recon_loss,total_kl_loss=0.,0.,0.\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i,(inputs, _) in enumerate(loader):\n",
    "\t\t\tif i == stop_iter:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tinputs = Variable(inputs).view(inputs.size()[0],inputs.size()[1]) \n",
    "\t\t\tif cuda:\n",
    "\t\t\t\tinputs = inputs.cuda()\n",
    "\t\t\toutput, mean, logvar = model(inputs)\n",
    "\t\t\tloss, reconstruction_loss, kl_loss = vae_loss(output, inputs, mean, logvar, loss_func, epoch, kl_warm_up, beta)\n",
    "\t\t\ttotal_loss+=loss.item()\n",
    "\t\t\ttotal_recon_loss+=reconstruction_loss.item()\n",
    "\t\t\ttotal_kl_loss+=kl_loss.item()\n",
    "\treturn model, total_loss,total_recon_loss,total_kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_vae(model, loader, cuda=True):\n",
    "\tprint(model)\n",
    "\tmodel.eval()\n",
    "\tfinal_outputs=[]\n",
    "\twith torch.no_grad():\n",
    "\t\tfor inputs, outcomes in loader:\n",
    "\t\t\tinputs = Variable(inputs).view(inputs.size()[0],inputs.size()[1]) # modify for convolutions, add batchnorm2d?\n",
    "\t\t\tif cuda:\n",
    "\t\t\t\tinputs = inputs.cuda()\n",
    "\t\t\tz = np.squeeze(model.get_latent_z(inputs).detach().cpu().numpy())\n",
    "\t\t\tfinal_outputs.append(z)\n",
    "\t\tz=np.vstack(final_outputs)\n",
    "\treturn z, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AutoEncoder:\n",
    "\tdef __init__(self, autoencoder_model, n_epochs, loss_fn, optimizer, cuda=True, kl_warm_up=0, beta=1.,scheduler_opts={}):\n",
    "\t\tself.model=autoencoder_model\n",
    "\t\tif cuda:\n",
    "\t\t\tself.model = self.model.cuda()\n",
    "\t\tself.n_epochs = n_epochs\n",
    "\t\tself.loss_fn = loss_fn\n",
    "\t\tself.optimizer = optimizer\n",
    "\t\tself.cuda = cuda\n",
    "\t\tself.kl_warm_up = kl_warm_up\n",
    "\t\tself.beta=beta\n",
    "\t\tself.scheduler = Scheduler(self.optimizer,scheduler_opts) if scheduler_opts else Scheduler(self.optimizer)\n",
    "\t\tself.vae_animation_fname='animation.mp4'\n",
    "\t\tself.loss_plt_fname='loss.png'\n",
    "\t\tself.plot_interval=5\n",
    "\t\tself.embed_interval=200\n",
    "\t\tself.validation_set = False\n",
    "\n",
    "\tdef fit(self, train_data):\n",
    "\t\tloss_list = []\n",
    "\t\tmodel = self.model\n",
    "\t\tbest_model=copy.deepcopy(self.model)\n",
    "\t\tanimation_plts=[]\n",
    "\t\tplt_data={'kl_loss':[],'recon_loss':[],'lr':[],'val_kl_loss':[],'val_recon_loss':[], 'val_loss':[]}\n",
    "\t\tfor epoch in range(self.n_epochs):\n",
    "\t\t\tmodel, loss, recon_loss, kl_loss = train_vae(model, train_data, self.loss_fn, self.optimizer, self.cuda, epoch, self.kl_warm_up, self.beta)\n",
    "\t\t\tself.scheduler.step()\n",
    "\t\t\tplt_data['kl_loss'].append(kl_loss)\n",
    "\t\t\tplt_data['recon_loss'].append(recon_loss)\n",
    "\t\t\tplt_data['lr'].append(self.scheduler.get_lr())\n",
    "\t\t\tprint(\"Epoch {}: Loss {}, Recon Loss {}, KL-Loss {}\".format(epoch,loss,recon_loss,kl_loss))\n",
    "\t\t\tif self.validation_set:\n",
    "\t\t\t\tmodel, val_loss, val_recon_loss, val_kl_loss = val_vae(model, self.validation_set, self.loss_fn, self.optimizer, self.cuda, epoch, self.kl_warm_up, self.beta)\n",
    "\t\t\t\tplt_data['val_kl_loss'].append(val_kl_loss)\n",
    "\t\t\t\tplt_data['val_recon_loss'].append(val_recon_loss)\n",
    "\t\t\t\tplt_data['val_loss'].append(val_loss)\n",
    "\t\t\t\tprint(\"Epoch {}: Val-Loss {}, Val-Recon Loss {}, Val-KL-Loss {}\".format(epoch,val_loss,val_recon_loss,val_kl_loss))\n",
    "\t\t\tif epoch >= self.kl_warm_up:\n",
    "\t\t\t\tloss = loss if not self.validation_set else val_loss\n",
    "\t\t\t\tloss_list.append(loss)\n",
    "\t\t\t\tif loss <= min(loss_list): # next get models for lowest reconstruction and kl, 3 models\n",
    "\t\t\t\t\tbest_model=copy.deepcopy(model)#.state_dict())\n",
    "\t\t\t\t\tbest_epoch=epoch\n",
    "\t\t\t\tif 0 and epoch % self.embed_interval == 0:\n",
    "\t\t\t\t\tz,samples,outcomes=project_vae(best_model, train_data if not self.validation_set else self.validation_set, self.cuda)\n",
    "\t\t\t\t\tbeta_df=pd.DataFrame(z,index=samples)\n",
    "\t\t\t\t\tplotly_plot(umap_embed(beta_df,outcomes,n_neighbors=8,supervised=False,min_dist=0.2,metric='euclidean'),'training_{}.html'.format(best_epoch))\n",
    "\t\t\tif 0 and self.plot_interval and epoch % self.plot_interval == 0:\n",
    "\t\t\t\tz,_,outcomes=project_vae(model, train_data, self.cuda)\n",
    "\t\t\t\tanimation_plts.append(Plot('Latent Embedding, epoch {}'.format(epoch),\n",
    "\t\t\t\t\t\tdata=PlotTransformer(z,LabelEncoder().fit_transform(outcomes)).transform()))\n",
    "\t\tif 0:\n",
    "\t\t\tplts=Plotter([Plot(k,'epoch','lr' if 'loss' not in k else k,\n",
    "\t\t\t\t\t\t  pd.DataFrame(np.vstack((range(len(plt_data[k])),plt_data[k])).T,\n",
    "\t\t\t\t\t\t\t\t\t   columns=['x','y'])) for k in plt_data if plt_data[k]],animation=False)\n",
    "\t\t\tplts.write_plots(self.loss_plt_fname)\n",
    "\t\tif 0 and self.plot_interval:\n",
    "\t\t\tPlotter(animation_plts).write_plots(self.vae_animation_fname)\n",
    "\t\tself.min_loss = min(np.array(plt_data['kl_loss'])+np.array(plt_data['recon_loss']))\n",
    "\t\tif self.validation_set:\n",
    "\t\t\tself.min_val_loss = plt_data['val_loss'][best_epoch]\n",
    "\t\t\tself.min_val_kl_loss = plt_data['val_kl_loss'][best_epoch]\n",
    "\t\t\tself.min_val_recon_loss = plt_data['val_recon_loss'][best_epoch]\n",
    "\t\telse:\n",
    "\t\t\tself.min_val_loss, self.min_val_kl_loss, self.min_val_recon_loss  = -1.,-1.,-1.\n",
    "\t\tself.best_epoch = best_epoch\n",
    "\t\tself.model = best_model#self.model.load_state_dict(best_model)\n",
    "\t\tself.training_plot_data = plt_data\n",
    "\t\treturn self\n",
    "\n",
    "\tdef add_validation_set(self, validation_data):\n",
    "\t\tself.validation_set=validation_data\n",
    "\n",
    "\tdef transform(self, train_data):\n",
    "\t\treturn project_vae(self.model, train_data, self.cuda)\n",
    "\n",
    "\tdef fit_transform(self, train_data):\n",
    "\t\treturn self.fit(train_data).transform(train_data)\n",
    "\n",
    "\tdef generate(self, train_data):\n",
    "\t\tself.model.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tX_hat=[]\n",
    "\t\t\tfor i,(X,_) in enumerate(train_data):\n",
    "\t\t\t\tif self.cuda:\n",
    "\t\t\t\t\tX=X.cuda()\n",
    "\t\t\t\tX_hat.append(self.model(X)[0].detach().cpu())\n",
    "\t\t\tX_hat=torch.cat(X_hat,0).numpy()\n",
    "\t\treturn X_hat\n",
    "\n",
    "def vae_loss(output, input, mean, logvar, loss_func, epoch, kl_warm_up=0, beta=1.):\n",
    "\tif type(output) != type([]):\n",
    "\t\toutput = [output]\n",
    "\trecon_loss = sum([loss_func(out, input) for out in output])\n",
    "\tkl_loss = torch.mean(0.5 * torch.sum(\n",
    "\t\ttorch.exp(logvar) + mean**2 - 1. - logvar, 1))\n",
    "\tkl_loss *= beta\n",
    "\tif epoch < kl_warm_up:\n",
    "\t\tkl_loss *= np.clip(epoch/kl_warm_up,0.,1.)\n",
    "\t#print(recon_loss,kl_loss)\n",
    "\treturn recon_loss + kl_loss, recon_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TybaltTitusVAE(nn.Module):\n",
    "\tdef __init__(self, n_input, n_latent, hidden_layer_encoder_topology=[100,100,100], cuda=False):\n",
    "\t\tsuper(TybaltTitusVAE, self).__init__()\n",
    "\t\tself.n_input = n_input\n",
    "\t\tself.n_latent = n_latent\n",
    "\t\tself.cuda_on = cuda\n",
    "\t\tself.pre_latent_topology = [n_input]+(hidden_layer_encoder_topology if hidden_layer_encoder_topology else [])\n",
    "\t\tself.post_latent_topology = [n_latent]+(hidden_layer_encoder_topology[::-1] if hidden_layer_encoder_topology else [])\n",
    "\t\tself.encoder_layers = []\n",
    "\t\tif len(self.pre_latent_topology)>1:\n",
    "\t\t\tfor i in range(len(self.pre_latent_topology)-1):\n",
    "\t\t\t\tlayer = nn.Linear(self.pre_latent_topology[i],self.pre_latent_topology[i+1])\n",
    "\t\t\t\ttorch.nn.init.xavier_uniform_(layer.weight)\n",
    "\t\t\t\tself.encoder_layers.append(nn.Sequential(layer,nn.ReLU()))\n",
    "\t\tself.encoder = nn.Sequential(*self.encoder_layers) if self.encoder_layers else nn.Dropout(p=0.)\n",
    "\t\tself.z_mean = nn.Sequential(nn.Linear(self.pre_latent_topology[-1],n_latent),nn.BatchNorm1d(n_latent))\n",
    "\t\tself.z_var = nn.Sequential(nn.Linear(self.pre_latent_topology[-1],n_latent),nn.BatchNorm1d(n_latent))\n",
    "\t\tself.z_develop = nn.Linear(n_latent,self.pre_latent_topology[-1])\n",
    "\t\tself.decoder_layers = []\n",
    "\t\tif len(self.post_latent_topology)>1:\n",
    "\t\t\tfor i in range(len(self.post_latent_topology)-1):\n",
    "\t\t\t\tlayer = nn.Linear(self.post_latent_topology[i],self.post_latent_topology[i+1])\n",
    "\t\t\t\ttorch.nn.init.xavier_uniform_(layer.weight)\n",
    "\t\t\t\tself.decoder_layers.append(nn.Sequential(layer,nn.ReLU()))\n",
    "\t\tself.decoder_layers = nn.Sequential(*self.decoder_layers)\n",
    "\t\tself.output_layer = nn.Sequential(nn.Linear(self.post_latent_topology[-1],n_input),nn.Sigmoid())\n",
    "\t\tif self.decoder_layers:\n",
    "\t\t\tself.decoder = nn.Sequential(*[self.decoder_layers,self.output_layer])\n",
    "\t\telse:\n",
    "\t\t\tself.decoder = self.output_layer\n",
    "\n",
    "\tdef sample_z(self, mean, logvar):\n",
    "\t\tstddev = torch.exp(0.5 * logvar)\n",
    "\t\tnoise = Variable(torch.randn(stddev.size()))\n",
    "\t\tif self.cuda_on:\n",
    "\t\t\tnoise=noise.cuda()\n",
    "\t\tif not self.training:\n",
    "\t\t\tnoise = 0.\n",
    "\t\t\tstddev = 0.\n",
    "\t\treturn (noise * stddev) + mean\n",
    "\n",
    "\tdef encode(self, x):\n",
    "\t\tx = self.encoder(x)\n",
    "\t\tmean = self.z_mean(x)\n",
    "\t\tvar = self.z_var(x)\n",
    "\t\treturn mean, var\n",
    "\n",
    "\tdef decode(self, z):\n",
    "\t\tout = self.decoder(z)\n",
    "\t\treturn out\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tmean, logvar = self.encode(x)\n",
    "\t\tz = self.sample_z(mean, logvar)\n",
    "\t\tout = self.decode(z)\n",
    "\t\treturn out, mean, logvar\n",
    "\n",
    "\tdef get_latent_z(self, x):\n",
    "\t\tmean, logvar = self.encode(x)\n",
    "\t\treturn self.sample_z(mean, logvar)\n",
    "\n",
    "\tdef forward_predict(self, x):\n",
    "\t\treturn self.get_latent_z(x)\n",
    "\n",
    "def train_mlp(model, loader, loss_func, optimizer_vae, optimizer_mlp, cuda=True, categorical=False, train_decoder=False):\n",
    "\tmodel.train(True)\n",
    "\n",
    "\t#model.vae.eval() also freeze for depth of tuning?\n",
    "\t#print(loss_func)\n",
    "\tstop_iter = loader.dataset.length // loader.batch_size\n",
    "\trunning_loss=0.\n",
    "\trunning_decoder_loss=0.\n",
    "\tfor i,(inputs, y_true) in enumerate(loader): # change dataloder for classification/regression tasks\n",
    "\t\t#print(samples)\n",
    "\t\tif inputs.size()[0] == 1 and i == stop_iter:\n",
    "\t\t\tbreak\n",
    "\t\tinputs = Variable(inputs).view(inputs.size()[0],inputs.size()[1])\n",
    "\t\ty_true = Variable(y_true)\n",
    "\t\tif categorical:\n",
    "\t\t\ty_true=y_true.argmax(1).long()\n",
    "\t\t#print(inputs.size())\n",
    "\t\tif cuda:\n",
    "\t\t\tinputs = inputs.cuda()\n",
    "\t\t\ty_true = y_true.cuda()\n",
    "\t\ty_predict, z = model(inputs)\n",
    "\t\tloss = loss_func(y_predict,y_true)\n",
    "\n",
    "\t\toptimizer_vae.zero_grad()\n",
    "\t\toptimizer_mlp.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\tif train_decoder:\n",
    "\t\t\tmodel, decoder_loss = train_decoder_(model, inputs, z)\n",
    "\t\t\trunning_decoder_loss += decoder_loss\n",
    "\t\toptimizer_vae.step()\n",
    "\t\toptimizer_mlp.step()\n",
    "\t\trunning_loss+=loss.item()\n",
    "\tif train_decoder:\n",
    "\t\tprint('Decoder Loss is {}'.format(running_decoder_loss))\n",
    "\treturn model, running_loss\n",
    "\n",
    "def val_mlp(model, loader, loss_func, cuda=True, categorical=False, train_decoder=False):\n",
    "\tmodel.eval()\n",
    "\n",
    "\t#model.vae.eval() also freeze for depth of tuning?\n",
    "\tstop_iter = loader.dataset.length // loader.batch_size\n",
    "\trunning_decoder_loss=0.\n",
    "\trunning_loss=0.\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i,(inputs, y_true) in enumerate(loader): # change dataloder for classification/regression tasks\n",
    "\t\t\tif inputs.size()[0] == 1 and i == stop_iter:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tinputs = Variable(inputs).view(inputs.size()[0],inputs.size()[1])\n",
    "\t\t\ty_true = Variable(y_true)\n",
    "\t\t\t#print(inputs.size())\n",
    "\t\t\tif categorical:\n",
    "\t\t\t\ty_true=y_true.argmax(1).long()\n",
    "\t\t\tif cuda:\n",
    "\t\t\t\tinputs = inputs.cuda()\n",
    "\t\t\t\ty_true = y_true.cuda()\n",
    "\t\t\ty_predict, z = model(inputs)\n",
    "\t\t\tloss = loss_func(y_predict,y_true)\n",
    "\t\t\trunning_loss+=loss.item()\n",
    "\t\t\tif train_decoder:\n",
    "\t\t\t\trunning_decoder_loss += val_decoder_(model, inputs, z)\n",
    "\t\tif train_decoder:\n",
    "\t\t\tprint('Val Decoder Loss is {}'.format(running_decoder_loss))\n",
    "\treturn model, running_loss\n",
    "\n",
    "def test_mlp(model, loader, categorical, cuda=True, output_latent=True):\n",
    "\n",
    "\tmodel.eval()\n",
    "\tY_pred=[]\n",
    "\tfinal_latent=[]\n",
    "\tY_true=[]\n",
    "\twith torch.no_grad():\n",
    "\t\tfor inputs, y_true in loader: # change dataloder for classification/regression tasks\n",
    "\t\t\tprint(inputs)\n",
    "\t\t\tinputs = Variable(inputs).view(inputs.size()[0],inputs.size()[1])\n",
    "\t\t\ty_true = Variable(y_true)\n",
    "\t\t\t#print(inputs.size())\n",
    "\t\t\tif cuda:\n",
    "\t\t\t\tinputs = inputs.cuda()\n",
    "\t\t\t\ty_true = y_true.cuda()\n",
    "\t\t\ty_predict, z = model(inputs)\n",
    "\t\t\ty_predict=np.squeeze(y_predict.detach().cpu().numpy())\n",
    "\t\t\ty_true=np.squeeze(y_true.detach().cpu().numpy())\n",
    "\t\t\t#print(y_predict.shape,y_true.shape)\n",
    "\t\t\t#print(y_predict,y_true)\n",
    "\t\t\tif len(y_predict.shape) < 2:\n",
    "\t\t\t\ty_predict=y_predict.flatten()\n",
    "\t\t\tif len(y_true.shape) < 2:\n",
    "\t\t\t\ty_true=y_true.flatten()  # FIXME\n",
    "\t\t\tY_pred.append(y_predict)\n",
    "\t\t\tfinal_latent.append(np.squeeze(z.detach().cpu().numpy()))\n",
    "\t\t\tY_true.append(y_true)\n",
    "\tif len(Y_pred) > 1:\n",
    "\t\tif all(list(map(lambda x: len(np.shape(x))<2,Y_pred))):\n",
    "\t\t\tY_pred = np.hstack(Y_pred)[:,np.newaxis]\n",
    "\t\telse:\n",
    "\t\t\tY_pred=np.vstack(Y_pred)\n",
    "\telse:\n",
    "\t\tY_pred = Y_pred[0]\n",
    "\t\tif len(np.shape(Y_pred))<2:\n",
    "\t\t\tY_pred=Y_pred[:,np.newaxis]\n",
    "\tif len(final_latent) > 1:\n",
    "\t\tfinal_latent=np.vstack(final_latent)\n",
    "\telse:\n",
    "\t\tfinal_latent = final_latent[0]\n",
    "\tif len(Y_true) > 1:\n",
    "\t\tif all(list(map(lambda x: len(np.shape(x))<2,Y_true))):\n",
    "\t\t\tY_true = np.hstack(Y_true)[:,np.newaxis]\n",
    "\t\telse:\n",
    "\t\t\tY_true=np.vstack(Y_true)\n",
    "\telse:\n",
    "\t\tY_true = Y_true[0]\n",
    "\t\tif len(np.shape(Y_true))<2:\n",
    "\t\t\tY_true=Y_true[:,np.newaxis]\n",
    "\tprint(Y_pred,Y_true)\n",
    "\t#print(np.hstack([Y_pred,Y_true]))\n",
    "\tif output_latent:\n",
    "\t\treturn Y_pred, Y_true, final_latent, None\n",
    "\telse:\n",
    "\t\treturn Y_pred\n",
    "\n",
    "def train_decoder_(model, x, z):\n",
    "\tmodel.vae.train(True)\n",
    "\tfor param in model.parameters():\n",
    "\t\tparam.requires_grad = False\n",
    "\tfor param in model.vae.decoder.parameters():\n",
    "\t\tparam.requires_grad = True\n",
    "\tloss_fn = nn.BCELoss(reduction='sum')\n",
    "\tx_hat = model.decode(z)\n",
    "\tif type(x_hat) != type([]):\n",
    "\t\tx_hat = [x_hat]\n",
    "\tloss = sum([loss_func(x_h, x) for x_h in x_hat])\n",
    "\tloss.backward()\n",
    "\tfor param in model.parameters():\n",
    "\t\tparam.requires_grad = True\n",
    "\tmodel.vae.eval()\n",
    "\treturn model, loss.item()\n",
    "\n",
    "def val_decoder_(model, x, z):\n",
    "\tmodel.vae.eval()\n",
    "\tloss_fn = nn.BCELoss(reduction='sum')\n",
    "\tx_hat = model.decode(z)\n",
    "\tif type(x_hat) != type([]):\n",
    "\t\tx_hat = [x_hat]\n",
    "\tloss = sum([loss_func(x_h, x) for x_h in x_hat])\n",
    "\treturn loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPFinetuneVAE:\n",
    "\n",
    "\tdef __init__(self, mlp_model, n_epochs=None, loss_fn=None, optimizer_vae=None, optimizer_mlp=None, cuda=True, categorical=False, scheduler_opts={}, output_latent=True, train_decoder=False):\n",
    "\t\tself.model=mlp_model\n",
    "\t\t#print(self.model)\n",
    "\t\tself.model.vae.cuda_on = cuda\n",
    "\t\tif cuda:\n",
    "\t\t\tself.model = self.model.cuda()\n",
    "\t\t\t#self.model.vae = self.model.vae.cuda()\n",
    "\t\tself.n_epochs = n_epochs\n",
    "\t\tself.loss_fn = loss_fn\n",
    "\t\tself.optimizer_vae = optimizer_vae\n",
    "\t\tself.optimizer_mlp = optimizer_mlp\n",
    "\t\tself.cuda = cuda\n",
    "\t\tif self.optimizer_vae!=None and self.optimizer_mlp!=None:\n",
    "\t\t\tself.scheduler_vae = Scheduler(self.optimizer_vae,scheduler_opts) if scheduler_opts else Scheduler(self.optimizer_vae)\n",
    "\t\t\tself.scheduler_mlp = Scheduler(self.optimizer_mlp,scheduler_opts) if scheduler_opts else Scheduler(self.optimizer_mlp)\n",
    "\t\telse:\n",
    "\t\t\tself.scheduler_vae = None\n",
    "\t\t\tself.scheduler_mlp = None\n",
    "\t\tself.loss_plt_fname='loss.png'\n",
    "\t\tself.embed_interval=200\n",
    "\t\tself.validation_set = False\n",
    "\t\tself.return_latent = True\n",
    "\t\tself.categorical = categorical\n",
    "\t\tself.output_latent = output_latent\n",
    "\t\tself.train_decoder = train_decoder # FIXME add loss for decoder if selecting this option and freeze other weights when updating decoder, also change forward function to include reconstruction, change back when done\n",
    "\t\tself.train_fn = train_mlp\n",
    "\t\tself.val_fn = val_mlp\n",
    "\t\tself.test_fn = test_mlp\n",
    "\n",
    "\tdef fit(self, train_data):\n",
    "\t\tloss_list = []\n",
    "\t\tmodel = self.model\n",
    "\t\tprint(model)\n",
    "\t\tbest_model=copy.deepcopy(self.model)\n",
    "\t\tplt_data={'loss':[],'lr_vae':[],'lr_mlp':[], 'val_loss':[]}\n",
    "\t\tfor epoch in range(self.n_epochs):\n",
    "\t\t\tprint(epoch)\n",
    "\t\t\tmodel, loss = self.train_fn(model, train_data, self.loss_fn, self.optimizer_vae, self.optimizer_mlp, self.cuda,categorical=self.categorical, train_decoder=self.train_decoder)\n",
    "\t\t\tself.scheduler_vae.step()\n",
    "\t\t\tself.scheduler_mlp.step()\n",
    "\t\t\tplt_data['loss'].append(loss)\n",
    "\t\t\tprint(\"Epoch {}: Loss {}\".format(epoch,loss))\n",
    "\t\t\tif self.validation_set:\n",
    "\t\t\t\tmodel, val_loss = self.val_fn(model, self.validation_set, self.loss_fn, self.cuda,categorical=self.categorical, train_decoder=self.train_decoder)\n",
    "\t\t\t\tplt_data['val_loss'].append(val_loss)\n",
    "\t\t\t\tprint(\"Epoch {}: Val-Loss {}\".format(epoch,val_loss))\n",
    "\t\t\tplt_data['lr_vae'].append(self.scheduler_vae.get_lr())\n",
    "\t\t\tplt_data['lr_mlp'].append(self.scheduler_mlp.get_lr())\n",
    "\t\t\tloss = loss if not self.validation_set else val_loss\n",
    "\t\t\tloss_list.append(loss)\n",
    "\t\t\tif loss <= min(loss_list): # next get models for lowest reconstruction and kl, 3 models\n",
    "\t\t\t\tbest_model=copy.deepcopy(model)\n",
    "\t\t\t\tbest_epoch=epoch\n",
    "\t\tself.training_plot_data=plt_data\n",
    "\t\tif 0:\n",
    "\t\t\tplts=Plotter([Plot(k,'epoch','lr' if 'loss' not in k else k,\n",
    "\t\t\t\t\t\t  pd.DataFrame(np.vstack((range(len(plt_data[k])),plt_data[k])).T,\n",
    "\t\t\t\t\t\t\t\t\t   columns=['x','y'])) for k in plt_data if plt_data[k]],animation=False)\n",
    "\t\t\tplts.write_plots(self.loss_plt_fname)\n",
    "\t\tself.min_loss = min(plt_data['loss'])\n",
    "\t\tif self.validation_set:\n",
    "\t\t\tself.min_val_loss = min(plt_data['val_loss'])\n",
    "\t\telse:\n",
    "\t\t\tself.min_val_loss = -1\n",
    "\t\tself.best_epoch = best_epoch\n",
    "\t\tself.model = best_model\n",
    "\t\treturn self\n",
    "\n",
    "\tdef add_validation_set(self, validation_data):\n",
    "\t\tself.validation_set=validation_data\n",
    "\n",
    "\tdef predict(self, test_data):\n",
    "\t\treturn self.test_fn(self.model, test_data, self.categorical, self.cuda, self.output_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_MLP(nn.Module):\n",
    "\n",
    "\t# add ability to train decoderF\n",
    "\tdef __init__(self, vae_model, n_output, categorical=False, hidden_layer_topology=[100,100,100], dropout_p=0.2, add_softmax=False):\n",
    "\t\tsuper(VAE_MLP,self).__init__()\n",
    "\t\tself.vae = vae_model\n",
    "\t\tself.n_output = n_output\n",
    "\t\tself.categorical = categorical\n",
    "\t\tself.add_softmax = add_softmax\n",
    "\t\tself.topology = [self.vae.n_latent]+(hidden_layer_topology if hidden_layer_topology else [])\n",
    "\t\tself.mlp_layers = []\n",
    "\t\tself.dropout_p=dropout_p\n",
    "\t\tif len(self.topology)>1:\n",
    "\t\t\tfor i in range(len(self.topology)-1):\n",
    "\t\t\t\tlayer = nn.Linear(self.topology[i],self.topology[i+1])\n",
    "\t\t\t\ttorch.nn.init.xavier_uniform_(layer.weight)\n",
    "\t\t\t\tself.mlp_layers.append(nn.Sequential(layer,nn.ReLU(),nn.Dropout(self.dropout_p)))\n",
    "\t\tself.output_layer = nn.Linear(self.topology[-1],self.n_output)\n",
    "\t\ttorch.nn.init.xavier_uniform_(self.output_layer.weight)\n",
    "\t\tself.mlp_layers.extend([self.output_layer]+([nn.Softmax()] if self.add_softmax else []))#+([nn.LogSoftmax()] if self.categorical else []))\n",
    "\t\tself.mlp = nn.Sequential(*self.mlp_layers)\n",
    "\t\tself.output_z=False\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\tz=self.vae.get_latent_z(x)\n",
    "\t\treturn self.mlp(z), z\n",
    "\n",
    "\tdef decode(self,z):\n",
    "\t\treturn self.vae.decoder(z)\n",
    "\n",
    "\tdef forward_embed(self,x):\n",
    "\t\tout=self.vae.get_latent_z(x)\n",
    "\t\trecon=self.vae.decoder(out)\n",
    "\t\treturn self.mlp(out), out, recon\n",
    "\n",
    "\tdef toggle_latent_z(self):\n",
    "\t\tif self.output_z:\n",
    "\t\t\tself.output_z=False\n",
    "\t\telse:\n",
    "\t\t\tself.output_z=True\n",
    "\n",
    "\tdef forward_predict(self,x):\n",
    "\t\tif self.output_z:\n",
    "\t\t\treturn self.vae.get_latent_z(x)\n",
    "\t\telse:\n",
    "\t\t\treturn self.mlp(self.vae.get_latent_z(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\tdef __init__(self, n_input, hidden_topology, dropout_p, n_outputs=1, binary=True, softmax=False, relu_out=False):\n",
    "\t\tsuper(MLP,self).__init__()\n",
    "\t\tself.topology = [n_input]+hidden_topology+[n_outputs]\n",
    "\t\tlayers = [nn.Linear(self.topology[i],self.topology[i+1]) for i in range(len(self.topology)-2)]\n",
    "\t\tfor layer in layers:\n",
    "\t\t\ttorch.nn.init.xavier_uniform_(layer.weight)\n",
    "\t\tself.layers = [nn.Sequential(layer,nn.LeakyReLU(),nn.Dropout(p=dropout_p)) for layer in layers]\n",
    "\t\toutput_layer = nn.Linear(self.topology[-2],self.topology[-1])\n",
    "\t\ttorch.nn.init.xavier_uniform_(output_layer.weight)\n",
    "\t\tif binary:\n",
    "\t\t\toutput_transform = nn.Sigmoid()\n",
    "\t\telif softmax:\n",
    "\t\t\toutput_transform = nn.Softmax()\n",
    "\t\telif relu_out:\n",
    "\t\t\toutput_transform = nn.ReLU()\n",
    "\t\telse:\n",
    "\t\t\toutput_transform = nn.Dropout(p=0.)\n",
    "\t\tself.layers.append(nn.Sequential(output_layer,output_transform))\n",
    "\t\tself.mlp = nn.Sequential(*self.layers)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPTrainer:\n",
    "\tdef __init__(self, mlp_model, n_epoch=300, validation_dataloader=None, optimizer_opts=dict(name='adam',lr=1e-3,weight_decay=1e-4), scheduler_opts=dict(scheduler='warm_restarts',lr_scheduler_decay=0.5,T_max=10,eta_min=5e-8,T_mult=2), class_weights=np.array([]), loss_fn=None, categorical=False):\n",
    "\t\tself.mlp = mlp_model\n",
    "\t\toptimizers = {'adam':torch.optim.Adam, 'lbfgs':torch.optim.LBFGS}\n",
    "\t\tif 'name' not in list(optimizer_opts.keys()):\n",
    "\t\t\toptimizer_opts['name']='adam'\n",
    "\t\tself.optimizer = optimizers[optimizer_opts.pop('name')]\n",
    "\t\toptimizer_opts={k:v for k,v in optimizer_opts.items() if k in inspect.getargspec(self.optimizer.__init__).args}\n",
    "\t\tself.optimizer = self.optimizer(self.mlp.parameters(),**optimizer_opts)\n",
    "\t\tself.scheduler = Scheduler(optimizer=self.optimizer,opts=scheduler_opts)\n",
    "\t\tself.n_epoch = n_epoch\n",
    "\t\tself.validation_dataloader = validation_dataloader\n",
    "\t\tself.class_weights = class_weights\n",
    "\t\tself.loss_fn = loss_fn#loss_functions[loss_fn]\n",
    "\t\tself.categorical=categorical\n",
    "\n",
    "\tdef calc_loss(self, y_pred, y_true):\n",
    "\t\tloss=self.loss_fn(y_pred,y_true)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef train_loop(self, train_dataloder):\n",
    "\t\tself.mlp.train(True)\n",
    "\t\trunning_loss = 0.\n",
    "\t\tfor i, (X,y_true) in enumerate(train_dataloder):\n",
    "\t\t\tif torch.cuda.is_available():\n",
    "\t\t\t\tX=X.cuda()\n",
    "\t\t\t\ty_true=y_true.cuda()\n",
    "\t\t\tif self.categorical:\n",
    "\t\t\t\ty_true=y_true.argmax(1).long()\n",
    "\t\t\ty_pred = self.mlp(X)\n",
    "\t\t\tloss=self.calc_loss(y_pred,y_true)\n",
    "\t\t\ttrain_loss=loss.item()\n",
    "\t\t\trunning_loss += train_loss\n",
    "\t\t\tself.optimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tself.optimizer.step()\n",
    "\t\tself.scheduler.step()\n",
    "\t\treturn running_loss\n",
    "\n",
    "\tdef val_loop(self, val_dataloader):\n",
    "\t\tself.mlp.train(False)\n",
    "\t\trunning_loss = 0.\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor i, (X,y_true) in enumerate(val_dataloader):\n",
    "\t\t\t\tif torch.cuda.is_available():\n",
    "\t\t\t\t\tX=X.cuda()\n",
    "\t\t\t\t\ty_true=y_true.cuda()\n",
    "\t\t\t\tif self.categorical:\n",
    "\t\t\t\t\ty_true=y_true.argmax(1).long()\n",
    "\t\t\t\ty_pred = self.mlp(X)\n",
    "\t\t\t\tloss = self.calc_loss(y_pred,y_true)\n",
    "\t\t\t\tval_loss=loss.item()\n",
    "\t\t\t\trunning_loss += val_loss\n",
    "\t\treturn running_loss\n",
    "\n",
    "\tdef test_loop(self, test_dataloader):\n",
    "\t\tself.mlp.train(False)\n",
    "\t\ty_pred = []\n",
    "\t\trunning_loss = 0.\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor i, batch in enumerate(test_dataloader):\n",
    "\t\t\t\tX = batch[0]\n",
    "\t\t\t\tif torch.cuda.is_available():\n",
    "\t\t\t\t\tX=X.cuda()\n",
    "\t\t\t\ty_pred.append(self.mlp(X).detach().cpu())\n",
    "\t\t\ty_pred = torch.cat(y_pred,0).numpy()\n",
    "\t\t\tif self.categorical:\n",
    "\t\t\t\ty_pred=y_pred.argmax(1)\n",
    "\t\treturn y_pred\n",
    "\n",
    "\tdef fit(self, train_dataloader, verbose=True):\n",
    "\t\tval_losses = []\n",
    "\t\timportances = {}\n",
    "\t\tfor epoch in range(self.n_epoch):\n",
    "\t\t\ttrain_loss = self.train_loop(train_dataloader)\n",
    "\t\t\tval_loss = self.val_loop(self.validation_dataloader)\n",
    "\t\t\tval_losses.append(val_loss)\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(\"Epoch {}: Train Loss {}, Val Loss {}\".format(epoch,train_loss,val_loss))\n",
    "\t\t\tif val_loss <= min(val_losses):\n",
    "\t\t\t\tmin_val_loss = val_loss\n",
    "\t\t\t\tbest_epoch = epoch\n",
    "\t\t\t\tbest_model = copy.deepcopy(self.mlp)\n",
    "\t\tself.min_val_loss=min_val_loss\n",
    "\t\tself.best_epoch=best_epoch\n",
    "\t\tprint('Min Val Loss {}, Best Epoch {}'.format(min_val_loss,best_epoch))\n",
    "\t\tself.mlp = best_model\n",
    "\t\treturn self\n",
    "\n",
    "\tdef predict(self, test_dataloader):\n",
    "\t\ty_pred = self.test_loop(test_dataloader)\n",
    "\t\treturn y_pred\n",
    "\n",
    "\tdef fit_predict(self, train_dataloader, test_dataloader):\n",
    "\t\treturn self.fit(train_dataloader)[0].predict(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
